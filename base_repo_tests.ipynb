{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def format_time(seconds):\n",
    "\tmins, secs = divmod(seconds, 60)\n",
    "\thrs, mins = divmod(mins, 60)\n",
    "\treturn f\"{int(hrs):02d}:{int(mins):02d}:{int(secs):02d}\"\n",
    "transformer_name=\"Transformer\"\n",
    "nstransformer_name=\"Nonstationary_Transformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           Exchange_96_96      Model:              Transformer         \n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          ./dataset/exchange_rate/\n",
      "  Data Path:          exchange_rate.csv   Features:           M                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          48                  \n",
      "  Pred Len:           96                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             8                   Dec In:             8                   \n",
      "  C Out:              8                   d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               2048                \n",
      "  Moving Avg:         25                  Factor:             3                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "  Output Attention:   0                   \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       10                  Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                'Exp'               Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_Exchange_96_96_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5120\n",
      "val 665\n",
      "test 1422\n",
      "\titers: 100, epoch: 1 | loss: 0.1041339\n",
      "\tspeed: 0.5318s/iter; left time: 798.1955s\n",
      "Epoch: 1 cost time: 57.166579484939575\n",
      "Epoch: 1, Steps: 160 | Train Loss: 0.1350827 Vali Loss: 0.3865065 Test Loss: 0.5434893\n",
      "Validation loss decreased (inf --> 0.386507).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0557877\n",
      "\tspeed: 1.5814s/iter; left time: 2120.6973s\n",
      "Epoch: 2 cost time: 56.38603377342224\n",
      "Epoch: 2, Steps: 160 | Train Loss: 0.0611851 Vali Loss: 0.5184150 Test Loss: 0.6491496\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0420661\n",
      "\tspeed: 1.5716s/iter; left time: 1856.0199s\n",
      "Epoch: 3 cost time: 56.79172229766846\n",
      "Epoch: 3, Steps: 160 | Train Loss: 0.0433635 Vali Loss: 0.6009043 Test Loss: 0.7216809\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0341029\n",
      "\tspeed: 1.5795s/iter; left time: 1612.7123s\n",
      "Epoch: 4 cost time: 56.797754526138306\n",
      "Epoch: 4, Steps: 160 | Train Loss: 0.0373526 Vali Loss: 0.6239295 Test Loss: 0.7804490\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_Exchange_96_96_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1422\n",
      "test shape: (1422, 96, 8) (1422, 96, 8)\n",
      "test shape: (1422, 96, 8) (1422, 96, 8)\n",
      "mse:0.5403108596801758, mae:0.5727508068084717, dtw:-999\n",
      "True\n",
      "Args in experiment:\n",
      "\u001b[1mBasic Config\u001b[0m\n",
      "  Task Name:          long_term_forecast  Is Training:        1                   \n",
      "  Model ID:           Exchange_96_96      Model:              Nonstationary_Transformer\n",
      "\n",
      "\u001b[1mData Loader\u001b[0m\n",
      "  Data:               custom              Root Path:          ./dataset/exchange_rate/\n",
      "  Data Path:          exchange_rate.csv   Features:           M                   \n",
      "  Target:             OT                  Freq:               h                   \n",
      "  Checkpoints:        ./checkpoints/      \n",
      "\n",
      "\u001b[1mForecasting Task\u001b[0m\n",
      "  Seq Len:            96                  Label Len:          48                  \n",
      "  Pred Len:           96                  Seasonal Patterns:  Monthly             \n",
      "  Inverse:            0                   \n",
      "\n",
      "\u001b[1mModel Parameters\u001b[0m\n",
      "  Top k:              5                   Num Kernels:        6                   \n",
      "  Enc In:             8                   Dec In:             8                   \n",
      "  C Out:              8                   d model:            512                 \n",
      "  n heads:            8                   e layers:           2                   \n",
      "  d layers:           1                   d FF:               2048                \n",
      "  Moving Avg:         25                  Factor:             3                   \n",
      "  Distil:             1                   Dropout:            0.1                 \n",
      "  Embed:              timeF               Activation:         gelu                \n",
      "  Output Attention:   0                   \n",
      "\n",
      "\u001b[1mRun Parameters\u001b[0m\n",
      "  Num Workers:        10                  Itr:                1                   \n",
      "  Train Epochs:       10                  Batch Size:         32                  \n",
      "  Patience:           3                   Learning Rate:      0.0001              \n",
      "  Des:                'Exp'               Loss:               MSE                 \n",
      "  Lradj:              type1               Use Amp:            0                   \n",
      "\n",
      "\u001b[1mGPU\u001b[0m\n",
      "  Use GPU:            1                   GPU:                0                   \n",
      "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
      "\n",
      "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
      "  P Hidden Dims:      256, 256            P Hidden Layers:    2                   \n",
      "\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_Exchange_96_96_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_'Exp'_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5120\n",
      "val 665\n",
      "test 1422\n",
      "\titers: 100, epoch: 1 | loss: 0.0641957\n",
      "\tspeed: 0.5401s/iter; left time: 810.7135s\n",
      "Epoch: 1 cost time: 58.16355776786804\n",
      "Epoch: 1, Steps: 160 | Train Loss: 0.1040988 Vali Loss: 0.1961163 Test Loss: 0.1303311\n",
      "Validation loss decreased (inf --> 0.196116).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.0696455\n",
      "\tspeed: 1.6049s/iter; left time: 2152.1165s\n",
      "Epoch: 2 cost time: 57.51271176338196\n",
      "Epoch: 2, Steps: 160 | Train Loss: 0.0496290 Vali Loss: 0.2082334 Test Loss: 0.1736733\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.0234062\n",
      "\tspeed: 1.5916s/iter; left time: 1879.6480s\n",
      "Epoch: 3 cost time: 57.15161895751953\n",
      "Epoch: 3, Steps: 160 | Train Loss: 0.0342813 Vali Loss: 0.2270227 Test Loss: 0.1825287\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.0212658\n",
      "\tspeed: 1.5793s/iter; left time: 1612.4956s\n",
      "Epoch: 4 cost time: 56.98224711418152\n",
      "Epoch: 4, Steps: 160 | Train Loss: 0.0299106 Vali Loss: 0.2354628 Test Loss: 0.1869244\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_Exchange_96_96_Nonstationary_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_'Exp'_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1422\n",
      "test shape: (1422, 96, 8) (1422, 96, 8)\n",
      "test shape: (1422, 96, 8) (1422, 96, 8)\n",
      "mse:0.12883011996746063, mae:0.2526378035545349, dtw:-999\n",
      "Notebook execution succeeded in 00:22:55.\n"
     ]
    }
   ],
   "source": [
    "notebook_start_time = time.time()\n",
    "\n",
    "%run -i ./run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/exchange_rate/ \\\n",
    "  --data_path exchange_rate.csv \\\n",
    "  --model_id Exchange_96_96 \\\n",
    "  --model $transformer_name \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 8 \\\n",
    "  --dec_in 8 \\\n",
    "  --c_out 8 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1\n",
    "\n",
    "%run -i ./run.py \\\n",
    "  --task_name long_term_forecast \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/exchange_rate/ \\\n",
    "  --data_path exchange_rate.csv \\\n",
    "  --model_id Exchange_96_96 \\\n",
    "  --model $nstransformer_name \\\n",
    "  --data custom \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --label_len 48 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --d_layers 1 \\\n",
    "  --factor 3 \\\n",
    "  --enc_in 8 \\\n",
    "  --dec_in 8 \\\n",
    "  --c_out 8 \\\n",
    "  --des 'Exp' \\\n",
    "  --itr 1 \\\n",
    "  --p_hidden_dims 256 256 \\\n",
    "  --p_hidden_layers 2\n",
    "\n",
    "# Record the end time\n",
    "notebook_end_time = time.time()\n",
    "\n",
    "# Calculate the duration\n",
    "notebook_duration = notebook_end_time - notebook_start_time\n",
    "print(f\"Notebook execution succeeded in {format_time(notebook_duration)}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
